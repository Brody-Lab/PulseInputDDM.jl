{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook walks through the basics of generating synthetic choice data and fitting the model to that data to recover the paramaters that generated it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting these models to data to choice data alone can be computational expensive. We fit the model below using 44 cpus.\n",
    "\n",
    "`using` is the julia version of python's `import`, i.e. in incorporates the exported functions of a module into the current namespace. `Distributed` is a julia module for performing parallel computing. `addprocs()` adds some workers, which can be called by a main process if there are calls to do things in parallel. `PulseInputDDM` parallelizes the computation of the log-likelhood across trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(8);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Fitting a choice model.\n",
    "\n",
    "when `using` is called after workers have been made, i.e. above, then those modules are available on all the workers (i.e. any function called from those modules will be able to be executed on any worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using PulseInputDDM, Flatten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some data\n",
    "\n",
    "Create an instance of the `θchoice` [composite type](https://docs.julialang.org/en/v1/manual/types/#Composite-Types) which contains the 9 parameters of a choice DDM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_syn = θchoice(θz=θz(σ2_i = 1., B = 13., λ = -0.5, σ2_a = 10., σ2_s = 1.0,\n",
    "    ϕ = 0.4, τ_ϕ = 0.02), bias=0.1, lapse=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgen = collect(Flatten.flatten(θ_syn));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 8K trials of the synthetic data using those parameters. change `rng` to get a different set with the same parameters. `dt` specifies the temporal binning of the data. `1e-2` has worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data = synthetic_data(;θ=θ_syn, ntrials=8_000, rng=2, dt=1e-2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PulseInputDDM` computes the log-likelihood by propogating mass of the latent distribution in time. This is done numerically by dividing the distribution up into little temporal and spatial bins. `n` is the number of spatials bins to use. `n=53` seems to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 53"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `choiceDDM` composite type which contains the parameters and the data of a choice DDM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choiceDDM{θchoice{θz{Float64}, Float64}}\n",
       "  θ: θchoice{θz{Float64}, Float64}\n",
       "  n: Int64 53\n",
       "  cross: Bool false\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_gen = choiceDDM(θ=θ_syn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loglikelihood of the model under the generative parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2969.9823448565967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loglikelihood(model_gen, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = vcat([0.1, 15., -0.1, 20., 0.5, 0.2, 0.008], [0.,0.01]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `Flatten.reconstruct` to place the intial state into the `θchoice()` type, with each variable going into the right place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "θchoice{θz{Float64}, Float64}\n",
       "  θz: θz{Float64}\n",
       "  bias: Float64 0.0\n",
       "  lapse: Float64 0.01\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "θ = Flatten.reconstruct(θchoice(), x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = choiceDDM(θ=θ);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loglikelihood of the model under the initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3473.431290856813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loglikelihood(model, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `choiceoptions` composite type, using `lb`, `ub`, and `fit`. `choiceoptions` specifies which parameters to fit, and the lower and upper bounds of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = choiceoptions(fit=fit, lb=lb, ub=ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choiceoptions\n",
       "  fit: Array{Bool}((9,)) Bool[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "  lb: Array{Float64}((9,)) [0.0, 2.0, -5.0, 0.0, 0.0, 0.0, 0.005, -5.0, 0.0]\n",
       "  ub: Array{Float64}((9,)) [30.0, 100.0, 5.0, 200.0, 10.0, 1.2, 1.0, 5.0, 1.0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = choiceoptions(lb=vcat([0., 2.,  -5., 0.,   0.,  0., 0.005, -5.0, 0.0]),\n",
    "    ub = [30., 100., 5., 200., 10., 1.2,  1., 5.0, 1.0], \n",
    "    fit = trues(9))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bounds for each parameter for the optimization. Some of these are strict (i.e. variance > 0) and some are not (B < 100 seems reasonable, but B could of course be larger then 100.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the model, using the options to define details of the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fminbox\n",
      "-------\n",
      "Initial mu = 0.160987\n",
      "\n",
      "Fminbox iteration 1\n",
      "-------------------\n",
      "Calling inner optimizer with mu = 0.160987\n",
      "\n",
      "(numbers below include barrier contribution)\n",
      "Iter     Function value   Gradient norm \n",
      "     0     3.481363e+03     5.400220e+04\n",
      " * Current step size: 1.0\n",
      " * time: 0.021502017974853516\n",
      " * g(x): [-23.743724932868748, -11.064054277815194, 24.1073365458685, -13.409269237364864, -667.8315427815999, 504.5657745923053, -54002.201879413646, -29.71329184576252, -17891.119702011783]\n",
      " * ~inv(H): [1.0 0.0 -0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 1.0 -0.0 0.0 0.0 0.0 0.0 0.0 0.0; -0.0 -0.0 1.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0; 0.0 0.0 -0.0 1.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 -0.0 0.0 1.0 0.0 0.0 0.0 0.0; 0.0 0.0 -0.0 0.0 0.0 1.0 0.0 0.0 0.0; 0.0 0.0 -0.0 0.0 0.0 0.0 1.0 0.0 0.0; 0.0 0.0 -0.0 0.0 0.0 0.0 0.0 1.0 0.0; 0.0 0.0 -0.0 0.0 0.0 0.0 0.0 0.0 1.0]\n",
      " * x: [0.1, 15.0, -0.1, 20.0, 0.5, 0.2, 0.008, 0.0, 0.01]\n"
     ]
    }
   ],
   "source": [
    "model, output = fit(model, data, options, f_tol=1e-6, iterations = 100, extended_trace=true, show_trace=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the likelihood of the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood(model, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the gradient of the model after optimization, to ensure we are near the minimum of the loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(model, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Hessian of the model, to compute confidence bounds around the ML parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Hessian(model, data)\n",
    "CI, HPSD = CIs(H);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the eigenvalues of the hessian, to ensure that it is positive semidefinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "eigvals(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = collect(Flatten.flatten(model.θ));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the solution is within the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xf - CI) .< xgen, (xf + CI) .> xgen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the step-by-step values of the optimization and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = hcat(map(x-> x.metadata[\"x\"], output.trace)...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 3,3\n",
    "fig, ax = subplots(num_rows, num_cols, figsize=(9,9))\n",
    "name = [\"σ2_i\", \"B\", \"λ\", \"σ2_a\", \"σ2_s\", \"ϕ\", \"τ_ϕ\", \"bias\", \"lapse\"]\n",
    "\n",
    "for i in 1:9\n",
    "                  \n",
    "    ax[i].plot(trace[i,:])\n",
    "    ax[i].plot(xgen[i] * ones(size(trace,2)))\n",
    "    ax[i].set_title(name[i])\n",
    "    \n",
    "    ax[i].errorbar(size(trace, 2), xf[i], yerr=CI[i], fmt=\"o\",\n",
    "        capsize=6)\n",
    "end\n",
    "\n",
    "tight_layout() \n",
    "display(gcf())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the LL over the optimization domain, for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere ℓℓ(x) = -PulseInputDDM.loglikelihood(x, model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "αs = hcat(map((lb,ub)-> range(lb + eps(), stop=ub, length=30), lb, ub));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_scan = map(i-> map(x-> ℓℓ(vcat(xf[1:i-1], x, xf[i+1:end])), αs[i]), 1:9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 3,3\n",
    "fig, ax = subplots(num_rows, num_cols, figsize=(9,9))\n",
    "name = [\"σ2_i\", \"B\", \"λ\", \"σ2_a\", \"σ2_s\", \"ϕ\", \"τ_ϕ\", \"bias\", \"lapse\"]\n",
    "\n",
    "for i in 1:9\n",
    "                  \n",
    "    ax[i].plot(αs[i], LL_scan[i], \"x\")\n",
    "    ax[i].set_title(name[i])\n",
    "    ax[i].plot(xgen[i]*ones(100), range(minimum(LL_scan[i]), stop=maximum(LL_scan[i]), length=100), \"k\")\n",
    "    ax[i].plot(xf[i]*ones(100), range(minimum(LL_scan[i]), stop=maximum(LL_scan[i]), length=100),\n",
    "        \"g--\")\n",
    "    ax[i].plot(max((xf[i] - CI[i]), lb[i]) *ones(100), range(minimum(LL_scan[i]), \n",
    "            stop=maximum(LL_scan[i]), length=100), \"r--\")\n",
    "    ax[i].plot(min((xf[i] + CI[i]), ub[i]) *ones(100), range(minimum(LL_scan[i]), \n",
    "            stop=maximum(LL_scan[i]), length=100), \"r--\")\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "tight_layout() \n",
    "display(gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
